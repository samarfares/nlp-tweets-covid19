{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular text analysis technique is called topic modeling. The ultimate goal of topic modeling is to find various topics that are present in your corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "In this notebook, we will be covering the steps on how to do **Latent Dirichlet Allocation (LDA)**, which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, you need to provide (1) a document-term matrix and (2) the number of topics you would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, your job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, you can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #1 (All Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aag</th>\n",
       "      <th>aarefajohari</th>\n",
       "      <th>aayega</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abattoirs</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbotts</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>...</th>\n",
       "      <th>來自</th>\n",
       "      <th>武汉肺炎</th>\n",
       "      <th>고양이</th>\n",
       "      <th>고양이스타그램</th>\n",
       "      <th>궈낙아쉥일축하훼</th>\n",
       "      <th>깍두기</th>\n",
       "      <th>제가</th>\n",
       "      <th>페르시아</th>\n",
       "      <th>𝗔𝘂𝘁𝗵𝗼𝗿𝘀</th>\n",
       "      <th>𝗧𝗶𝘁𝗹𝗲</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>april</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 9935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aag  aarefajohari  aayega  abandoned  abandons  abattoirs  abbott  \\\n",
       "april       0             0       1          3         0          0       0   \n",
       "february    0             0       0          0         0          0       0   \n",
       "january     0             0       0          0         0          0       0   \n",
       "july        0             0       0          0         0          1       0   \n",
       "june        1             0       0          0         0          0       1   \n",
       "march       0             0       0          0         1          0       0   \n",
       "may         0             1       0          0         0          0       0   \n",
       "\n",
       "          abbotts  abc  abcs  ...  來自  武汉肺炎  고양이  고양이스타그램  궈낙아쉥일축하훼  깍두기  제가  \\\n",
       "april           0    1     0  ...   0     0    0        0         0    0   0   \n",
       "february        0    0     1  ...   1     1    0        0         0    1   1   \n",
       "january         0    2     1  ...   0     0    0        0         0    0   0   \n",
       "july            0    5     0  ...   0     0    0        0         1    0   0   \n",
       "june            0    1     0  ...   0     0    0        0         0    0   0   \n",
       "march           1    0     0  ...   0     0    1        1         0    0   0   \n",
       "may             0    2     0  ...   0     0    0        0         0    0   0   \n",
       "\n",
       "          페르시아  𝗔𝘂𝘁𝗵𝗼𝗿𝘀  𝗧𝗶𝘁𝗹𝗲  \n",
       "april        0        0      0  \n",
       "february     1        0      0  \n",
       "january      0        0      0  \n",
       "july         0        0      0  \n",
       "june         0        1      1  \n",
       "march        0        0      0  \n",
       "may          0        0      0  \n",
       "\n",
       "[7 rows x 9935 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in our document-term matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>april</th>\n",
       "      <th>february</th>\n",
       "      <th>january</th>\n",
       "      <th>july</th>\n",
       "      <th>june</th>\n",
       "      <th>march</th>\n",
       "      <th>may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aarefajohari</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aayega</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandons</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              april  february  january  july  june  march  may\n",
       "aag               0         0        0     0     1      0    0\n",
       "aarefajohari      0         0        0     0     0      0    1\n",
       "aayega            1         0        0     0     0      0    0\n",
       "abandoned         3         0        0     0     0      0    0\n",
       "abandons          0         0        0     0     0      1    0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"china\" + 0.004*\"deaths\" + 0.003*\"health\" + 0.003*\"wuhan\" + 0.003*\"spread\" + 0.003*\"amp\" + 0.003*\"world\" + 0.003*\"outbreak\" + 0.003*\"time\" + 0.003*\"death\"'),\n",
       " (1,\n",
       "  '0.006*\"deaths\" + 0.003*\"fauci\" + 0.003*\"mask\" + 0.003*\"texas\" + 0.003*\"masks\" + 0.003*\"president\" + 0.003*\"going\" + 0.003*\"world\" + 0.003*\"china\" + 0.003*\"did\"'),\n",
       " (2,\n",
       "  '0.005*\"hoax\" + 0.005*\"china\" + 0.003*\"outbreak\" + 0.003*\"flu\" + 0.003*\"health\" + 0.003*\"said\" + 0.002*\"pence\" + 0.002*\"update\" + 0.002*\"dont\" + 0.002*\"confirmed\"'),\n",
       " (3,\n",
       "  '0.000*\"china\" + 0.000*\"health\" + 0.000*\"deaths\" + 0.000*\"going\" + 0.000*\"did\" + 0.000*\"world\" + 0.000*\"outbreak\" + 0.000*\"confirmed\" + 0.000*\"think\" + 0.000*\"spread\"')]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=80)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These topics aren't looking too great. We've tried modifying our parameters. Let's try modifying our terms list as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One popular trick is to look only at terms that are from one part of speech (only nouns, only adjectives, etc.). Check out the UPenn tag set: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' \n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>april</th>\n",
       "      <td>calls health sector hand profit crisis superch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february</th>\n",
       "      <td>i outbreak things s mexico canada hotel occupa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>cancels league dreamcatcher i liberals wall tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july</th>\n",
       "      <td>fyi surpasses york deaths day weekend start up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june</th>\n",
       "      <td>sport care access projects people lives devast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march</th>\n",
       "      <td>christians demons lives vulnerable attention m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>air risk home yourice risk cause cops hundreds...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text\n",
       "april     calls health sector hand profit crisis superch...\n",
       "february  i outbreak things s mexico canada hotel occupa...\n",
       "january   cancels league dreamcatcher i liberals wall tr...\n",
       "july      fyi surpasses york deaths day weekend start up...\n",
       "june      sport care access projects people lives devast...\n",
       "march     christians demons lives vulnerable attention m...\n",
       "may       air risk home yourice risk cause cops hundreds..."
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean.text.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aarefajohari</th>\n",
       "      <th>abattoirs</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbotts</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcs</th>\n",
       "      <th>abe</th>\n",
       "      <th>abeg</th>\n",
       "      <th>abets</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>來自</th>\n",
       "      <th>武汉肺炎</th>\n",
       "      <th>고양이</th>\n",
       "      <th>고양이스타그램</th>\n",
       "      <th>궈낙아쉥일축하훼</th>\n",
       "      <th>깍두기</th>\n",
       "      <th>제가</th>\n",
       "      <th>페르시아</th>\n",
       "      <th>𝗔𝘂𝘁𝗵𝗼𝗿𝘀</th>\n",
       "      <th>𝗧𝗶𝘁𝗹𝗲</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>april</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>february</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>july</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>june</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>may</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 5718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aarefajohari  abattoirs  abbott  abbotts  abc  abcs  abe  abeg  \\\n",
       "april                0          0       0        0    1     0    2     0   \n",
       "february             0          0       0        0    0     1    0     1   \n",
       "january              0          0       0        0    2     1    0     0   \n",
       "july                 0          1       0        0    4     0    0     0   \n",
       "june                 0          0       1        0    0     0    0     0   \n",
       "march                0          0       0        1    0     0    0     0   \n",
       "may                  1          0       0        0    1     0    0     0   \n",
       "\n",
       "          abets  ability  ...  來自  武汉肺炎  고양이  고양이스타그램  궈낙아쉥일축하훼  깍두기  제가  \\\n",
       "april         0        1  ...   0     0    0        0         0    0   0   \n",
       "february      0        1  ...   1     1    0        0         0    1   1   \n",
       "january       1        0  ...   0     0    0        0         0    0   0   \n",
       "july          0        0  ...   0     0    0        0         1    0   0   \n",
       "june          0        1  ...   0     0    0        0         0    0   0   \n",
       "march         0        0  ...   0     0    1        1         0    0   0   \n",
       "may           0        0  ...   0     0    0        0         0    0   0   \n",
       "\n",
       "          페르시아  𝗔𝘂𝘁𝗵𝗼𝗿𝘀  𝗧𝗶𝘁𝗹𝗲  \n",
       "april        0        0      0  \n",
       "february     1        0      0  \n",
       "january      0        0      0  \n",
       "july         0        0      0  \n",
       "june         0        1      1  \n",
       "march        0        0      0  \n",
       "may          0        0      0  \n",
       "\n",
       "[7 rows x 5718 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said', 'ppl', 'video', 'tweet']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.text)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"hedge\" + 0.004*\"pence\" + 0.003*\"bioweapon\" + 0.003*\"fear\" + 0.003*\"insertions\" + 0.003*\"novel\" + 0.003*\"flights\" + 0.002*\"cause\" + 0.002*\"humans\" + 0.002*\"asians\"'),\n",
       " (1,\n",
       "  '0.005*\"rioters\" + 0.005*\"protests\" + 0.005*\"dems\" + 0.004*\"lockdowns\" + 0.004*\"bigcity\" + 0.004*\"riots\" + 0.004*\"violence\" + 0.004*\"police\" + 0.003*\"cause\" + 0.003*\"recovery\"'),\n",
       " (2,\n",
       "  '0.007*\"lab\" + 0.004*\"agency\" + 0.003*\"unemployment\" + 0.002*\"job\" + 0.002*\"uk\" + 0.002*\"claims\" + 0.002*\"fauci\" + 0.002*\"facts\" + 0.002*\"intelligence\" + 0.002*\"april\"'),\n",
       " (3,\n",
       "  '0.006*\"fauci\" + 0.004*\"dr\" + 0.004*\"texas\" + 0.002*\"job\" + 0.002*\"infections\" + 0.002*\"surge\" + 0.002*\"joe\" + 0.002*\"hurricane\" + 0.002*\"hospitals\" + 0.002*\"florida\"')]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topic 0: hurricane Hanna\n",
    "* Topic 1: claims, fear and hedge\n",
    "* Topic 2: danger\n",
    "* Topic 3: protests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'april'),\n",
       " (0, 'february'),\n",
       " (0, 'january'),\n",
       " (3, 'july'),\n",
       " (3, 'june'),\n",
       " (3, 'march'),\n",
       " (1, 'may')]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each text contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmn.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a first pass of LDA, these kind of make sense to me, so we'll call it a day for now.\n",
    "* Topic 0:  hurricane Hanna [July]\n",
    "* Topic 1: claims, fear and hedge [January, February, March,April]\n",
    "* Topic 2: danger [June]\n",
    "* Topic 3: protests [May]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
